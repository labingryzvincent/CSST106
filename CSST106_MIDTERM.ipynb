{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/labingryzvincent/CSST106/blob/main/CSST106_MIDTERM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RYZ VINCENT LABING**\n",
        "\n",
        "**BSCS 4A**\n",
        "\n",
        "**CSST 106**\n",
        "\n",
        "**MIDTERM**"
      ],
      "metadata": {
        "id": "4NPIpiwE6cpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Setup Google Colab Environment**"
      ],
      "metadata": {
        "id": "QoCQEWWuIoes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have GPU support for faster training and testing\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9fte5CVH7zl",
        "outputId": "72c1a768-501b-4cf6-f783-6f6d3bcd44dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Clone the YOLOv3 Implementation**"
      ],
      "metadata": {
        "id": "U4dDoYA2Iqv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zzh8829/yolov3-tf2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhY7Tx3RIBIt",
        "outputId": "b9d759a7-6834-47f6-c2d2-b0f58117de04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3-tf2'...\n",
            "remote: Enumerating objects: 449, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 449 (delta 1), reused 0 (delta 0), pack-reused 442 (from 1)\u001b[K\n",
            "Receiving objects: 100% (449/449), 4.24 MiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (254/254), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Move into the project directory**"
      ],
      "metadata": {
        "id": "Y5Nf1G4BItN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov3-tf2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGIiv3SaIBLM",
        "outputId": "0f575858-56e4-44d1-c57f-67d3ebf13446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3-tf2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Install Dependencies**"
      ],
      "metadata": {
        "id": "YlmDrDZSIzH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install tensorflow-gpu==2.4.1  # Or the latest TensorFlow version supported on Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC4bLnyWIBNk",
        "outputId": "9e161c46-4475-417c-dd6b-f40df5475ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/yolov3-tf2 (from -r requirements.txt (line 6))\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow==2.11.1 (from -r requirements.txt (line 1))\n",
            "  Downloading tensorflow-2.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.2.0.32 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.2.0.32\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.4.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.4.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Download Pre-trained Weights**"
      ],
      "metadata": {
        "id": "u70u0iTPI2s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\n",
        "!python convert.py --weights ./data/yolov3.weights --output ./checkpoints/yolov3.tf --tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPmOtR47IBQE",
        "outputId": "9e85c303-01a6-4da0-cdaa-ef236b8efd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-05 04:05:38--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘data/yolov3.weights’\n",
            "\n",
            "data/yolov3.weights 100%[===================>] 236.52M  32.0MB/s    in 8.0s    \n",
            "\n",
            "2024-11-05 04:05:46 (29.7 MB/s) - ‘data/yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "2024-11-05 04:05:47.108904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-05 04:05:47.133529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-05 04:05:47.141076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-05 04:05:47.159319: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-05 04:05:48.460182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "\u001b[1mModel: \"yolov3_tiny\"\u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│ input (\u001b[94mInputLayer\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m)  │              \u001b[32m0\u001b[0m │ -                      │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_darknet (\u001b[94mFunctional\u001b[0m) │ [(\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,    │      \u001b[32m6,298,480\u001b[0m │ input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]            │\n",
            "│                           │ \u001b[32m256\u001b[0m), (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,     │                │                        │\n",
            "│                           │ \u001b[96mNone\u001b[0m, \u001b[32m1024\u001b[0m)]           │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_conv_0 (\u001b[94mFunctional\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,     │        \u001b[32m263,168\u001b[0m │ yolo_darknet[\u001b[32m0\u001b[0m][\u001b[32m1\u001b[0m]     │\n",
            "│                           │ \u001b[32m256\u001b[0m)                   │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_conv_1 (\u001b[94mFunctional\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,     │         \u001b[32m33,280\u001b[0m │ yolo_conv_0[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n",
            "│                           │ \u001b[32m384\u001b[0m)                   │                │ yolo_darknet[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_output_0             │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m,  │      \u001b[32m1,312,511\u001b[0m │ yolo_conv_0[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│ (\u001b[94mFunctional\u001b[0m)              │ \u001b[32m85\u001b[0m)                    │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_output_1             │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m,  │        \u001b[32m951,295\u001b[0m │ yolo_conv_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
            "│ (\u001b[94mFunctional\u001b[0m)              │ \u001b[32m85\u001b[0m)                    │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_boxes_0 (\u001b[94mLambda\u001b[0m)     │ [(\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, │              \u001b[32m0\u001b[0m │ yolo_output_0[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│                           │ \u001b[32m4\u001b[0m), (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, │                │                        │\n",
            "│                           │ \u001b[32m3\u001b[0m, \u001b[32m1\u001b[0m), (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,    │                │                        │\n",
            "│                           │ \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, \u001b[32m80\u001b[0m), (\u001b[96mNone\u001b[0m,   │                │                        │\n",
            "│                           │ \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, \u001b[32m4\u001b[0m)]     │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_boxes_1 (\u001b[94mLambda\u001b[0m)     │ [(\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, │              \u001b[32m0\u001b[0m │ yolo_output_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
            "│                           │ \u001b[32m4\u001b[0m), (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, │                │                        │\n",
            "│                           │ \u001b[32m3\u001b[0m, \u001b[32m1\u001b[0m), (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m,    │                │                        │\n",
            "│                           │ \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, \u001b[32m80\u001b[0m), (\u001b[96mNone\u001b[0m,   │                │                        │\n",
            "│                           │ \u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m3\u001b[0m, \u001b[32m4\u001b[0m)]     │                │                        │\n",
            "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
            "│ yolo_nms (\u001b[94mLambda\u001b[0m)         │ [(\u001b[32m1\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m4\u001b[0m), (\u001b[32m1\u001b[0m,     │              \u001b[32m0\u001b[0m │ yolo_boxes_0[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],    │\n",
            "│                           │ \u001b[96mNone\u001b[0m), (\u001b[32m1\u001b[0m, \u001b[96mNone\u001b[0m), (\u001b[32m1\u001b[0m)] │                │ yolo_boxes_0[\u001b[32m0\u001b[0m][\u001b[32m1\u001b[0m],    │\n",
            "│                           │                        │                │ yolo_boxes_0[\u001b[32m0\u001b[0m][\u001b[32m2\u001b[0m],    │\n",
            "│                           │                        │                │ yolo_boxes_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],    │\n",
            "│                           │                        │                │ yolo_boxes_1[\u001b[32m0\u001b[0m][\u001b[32m1\u001b[0m],    │\n",
            "│                           │                        │                │ yolo_boxes_1[\u001b[32m0\u001b[0m][\u001b[32m2\u001b[0m]     │\n",
            "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m8,858,734\u001b[0m (33.79 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m8,852,366\u001b[0m (33.77 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m6,368\u001b[0m (24.88 KB)\n",
            "I1105 04:05:52.053656 132315064643584 convert.py:24] model created\n",
            "I1105 04:05:52.054085 132315064643584 utils.py:44] yolo_darknet/conv2d bn\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov3-tf2/convert.py\", line 39, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/yolov3-tf2/convert.py\", line 26, in main\n",
            "    load_darknet_weights(yolo, FLAGS.weights, FLAGS.tiny)\n",
            "  File \"/content/yolov3-tf2/yolov3_tf2/utils.py\", line 49, in load_darknet_weights\n",
            "    in_dim = layer.get_input_shape_at(0)[-1]\n",
            "AttributeError: 'Conv2D' object has no attribute 'get_input_shape_at'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Dataset Preparation**"
      ],
      "metadata": {
        "id": "4K_KkxjsI55V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip train2017.zip -d ./data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D1z5js-IBSc",
        "outputId": "025fa665-1c0f-4c57-e055-b4a05496371b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-05 04:06:02--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 3.5.25.72, 54.231.231.65, 3.5.25.246, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|3.5.25.72|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘train2017.zip’\n",
            "\n",
            "train2017.zip        71%[=============>      ]  12.96G  34.5MB/s    eta 1m 54s "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Training YOLOv3**"
      ],
      "metadata": {
        "id": "mUkaRZF_I_Kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset ./data/train2017 --val_dataset ./data/val2017 \\\n",
        "                 --classes ./data/coco.names --num_classes 80 \\\n",
        "                 --mode fit --transfer true --batch_size 16 \\\n",
        "                 --epochs 10 --weights ./checkpoints/yolov3.tf"
      ],
      "metadata": {
        "id": "McjoMBR-IBUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik1KGUXvOJ7N",
        "outputId": "875c6ed3-0f6f-442e-bcb9-fb71ec9a3658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-20 10:59:02--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  32.9MB/s    in 7.8s    \n",
            "\n",
            "2024-10-20 10:59:10 (30.2 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2024-10-20 10:59:10--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-20 10:59:11 (39.3 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "--2024-10-20 10:59:11--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "coco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-20 10:59:11 (27.6 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Inference and Testing**"
      ],
      "metadata": {
        "id": "bBz0H4KfJFYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import YoloV3\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "from yolov3_tf2.dataset import transform_images\n",
        "\n",
        "# Load the YOLOv3 model\n",
        "yolo = YoloV3(classes=80)\n",
        "yolo.load_weights('yolov3.tf2')  # Ensure weights path is correct\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = \"kuto.jpg\"\n",
        "img_raw = tf.image.decode_image(open(image_path, 'rb').read(), channels=3)\n",
        "\n",
        "# Preprocess the image (resize to 416x416 for YOLOv3)\n",
        "img = tf.expand_dims(img_raw, 0)\n",
        "img = transform_images(img, 416)\n",
        "\n",
        "# Run inference\n",
        "boxes, scores, classes, nums = yolo(img)\n",
        "\n",
        "# Load class names (assuming you're using COCO dataset)\n",
        "class_names = [c.strip() for c in open('./data/coco.names').readlines()]\n",
        "\n",
        "# Draw bounding boxes on the image\n",
        "img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "\n",
        "# Save and display the output image\n",
        "cv2.imwrite('./output.jpg', img)\n",
        "\n",
        "# Display the image with detections\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(cv2.imread('./output.jpg'))"
      ],
      "metadata": {
        "id": "cTnppz-_Ny61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Visualize Results**"
      ],
      "metadata": {
        "id": "gtTySZ-AJJ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Display the image with detections\n",
        "cv2_imshow(cv2.imread('./output.jpg'))"
      ],
      "metadata": {
        "id": "jFTh74InIBZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10: Performance Evaluation**"
      ],
      "metadata": {
        "id": "c0MQphG_JM4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Measure inference time\n",
        "start_time = time.time()\n",
        "yolo(img)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Inference time: {end_time - start_time} seconds\")"
      ],
      "metadata": {
        "id": "etKfrnlXILl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}